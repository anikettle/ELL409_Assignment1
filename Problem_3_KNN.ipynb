{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import os\n",
    "import openCV as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10000, 4096, 1)\n(4096, 1)\n(8954, 4096, 1)\n(4096, 1)\n(10000, 4096, 1)\n(4096, 1)\n(10000, 4096, 1)\n(4096, 1)\n(10000, 4096, 1)\n(4096, 1)\n(10000, 4096, 1)\n(4096, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'E:\\ELL_Project\\problem3\\\\'\n",
    "lis_folders = os.listdir(data_dir+'.')[:-1]\n",
    "# print(lis_folders)\n",
    "X = []\n",
    "\n",
    "for folder in lis_folders:\n",
    "    lis_files = os.listdir(data_dir+folder+'\\.')\n",
    "    im = []\n",
    "    for files in lis_files:\n",
    "        img = '\\\\'.join([data_dir,folder,files])\n",
    "        image = plt.imread(img)\n",
    "        im.append(image.flatten().reshape(-1,1))\n",
    "    im_np = np.array(im)\n",
    "    X.append(im_np)\n",
    "for i in X:\n",
    "    print(i.shape)\n",
    "    print(i[0].shape)\n",
    "\n",
    "\n",
    "\n",
    "# X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 4096)\n",
      "(10000, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_edit = X[1]\n",
    "X_edit = np.array(X_edit)\n",
    "X_edit = X_edit[:,:,0]\n",
    "X_mean = np.sum(X_edit, axis=0) / X_edit.shape[0]\n",
    "X_mean = X_mean.reshape(1,-1)\n",
    "print(X_mean.shape)\n",
    "diff = X[0].shape[0]-X[1].shape[0]\n",
    "oneer = np.ones((diff,1))\n",
    "X_app = np.dot(oneer,X_mean)\n",
    "X_updated = np.append(X_edit,X_app,axis=0)\n",
    "print(X_updated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6, 10000, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_dash = X\n",
    "X_dash[1] = X_updated.reshape(-1,4096,1)\n",
    "X_np = np.array(X_dash)[:,:,:,0]\n",
    "print(X_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_data(X):\n",
    "    num_feats = X.shape[0]\n",
    "    for i in range(num_feats):\n",
    "        X_feat = X[i,:,:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(split_percent = 70):\n",
    "\n",
    "    split_point = split_percent//10\n",
    "\n",
    "    X_train = X[:(datasize*split_point)//10,:]\n",
    "    y_train = y[:(datasize*split_point)//10,:]\n",
    "    X_test = X[(datasize*split_point)//10:,:]\n",
    "    y_test = y[(datasize*split_point)//10:,:]\n",
    "\n",
    "    return(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train):\n",
    "    training_size = X_train.shape[0]\n",
    "    X_mean = np.sum(X_train,axis=0) / training_size\n",
    "    X_var = np.sqrt(np.sum((np.square(X_train-X_mean)),axis=0)/training_size)\n",
    "    X_train_reg = (X_train - X_mean) / X_var\n",
    "\n",
    "    return (X_mean,X_var,X_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,y_train,X_test,y_test,k_num,feat_scal=True):\n",
    "\n",
    "    test_size = X_test.shape[0]\n",
    "    train_size = X_train.shape[0]\n",
    "    # X_m,X_v,X_r,y_m,y_v,y_r = feature_scaling(X_train,y_train)\n",
    "    if feat_scal:\n",
    "        X_m,X_v,X_r = feature_scaling(X_train)\n",
    "        X_test_reg = (X_test-X_m)/X_v\n",
    "    else:\n",
    "        X_r = X_train\n",
    "        X_test_reg = X_test\n",
    "    # y_test_reg = (y_test-y_m)/y_v\n",
    "    y_pred = np.array([])\n",
    "    # print(y_pred)\n",
    "    for i in range(test_size):\n",
    "        sample_X = X_test_reg[i:i+1,:]\n",
    "        sample_y = y_test[i,:]\n",
    "        dist_vec = np.sqrt(np.sum(np.square(X_r-sample_X),axis=1))\n",
    "        dist_vec = dist_vec.reshape((train_size,1))\n",
    "\n",
    "        d = np.column_stack((dist_vec[:,:],y_train[:,0]))\n",
    "        # print(d)\n",
    "\n",
    "        sorted_dist = d[np.argsort(d[:, 0])]\n",
    "        temp_distance_vector = sorted_dist[:k_num,0]\n",
    "        distance_vector = temp_distance_vector.reshape(-1,1)\n",
    "        # distance_vector = np.append(np.ones(distance_vector.shape),distance_vector)\n",
    "        # print(distance_vector.shape)\n",
    "        for j in np.arange(0,10,0.5):\n",
    "            distance_vector = np.append(distance_vector,(temp_distance_vector**j).reshape(-1,1),axis=1)\n",
    "        distance_vector = distance_vector[:,1:]\n",
    "        # print(distance_vector.shape)\n",
    "        ddd = np.sum(distance_vector,axis=0).reshape(1,-1)\n",
    "        # print(ddd[0,0])\n",
    "        # print(ddd.shape)\n",
    "\n",
    "        y_val_vector = sorted_dist[:k_num,1].reshape(-1,1)\n",
    "        # print(y_val_vector.shape)\n",
    "        # print(distance_vector.shape)\n",
    "        # print(ddd.shape)\n",
    "        num1 = np.dot(np.transpose(y_val_vector),distance_vector) / ddd\n",
    "        # print(num1.shape)\n",
    "        # num1 = np.max(num1)\n",
    "        if i==0:\n",
    "            # print('check')\n",
    "            y_pred = num1.reshape(1,-1)\n",
    "        else:\n",
    "            # print(y_pred.shape)\n",
    "            y_pred = np.append(y_pred,num1.reshape(1,-1),axis=0)\n",
    "            \n",
    "\n",
    "    # print(y_pred.shape)\n",
    "    return y_pred\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_test):\n",
    "\n",
    "    # y_pred = y_pred.reshape(-1,1)\n",
    "    print('MSE LOSS')\n",
    "    mse_loss = np.sum(np.square((y_test-y_pred)),axis=0) / y_test.shape[0]\n",
    "    print(mse_loss)\n",
    "    print('............................................................................')\n",
    "    print('MAE LOSS')\n",
    "    mae_loss = np.sum(np.abs((y_test-y_pred)),axis=0) / y_test.shape[0]\n",
    "    print(mae_loss)\n",
    "    # print('............................................................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = import_dataset()\n",
    "y_pred = KNN(X_train,y_train,X_test,y_test,50,False)\n",
    "accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}