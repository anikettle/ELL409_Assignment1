{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt\n",
    "# import P\n",
    "import os\n",
    "# import openCV as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'E:\\ELL_Project\\problem3\\\\'\n",
    "lis_folders = os.listdir(data_dir+'.')[:-1]\n",
    "X = []\n",
    "cur_class = 0\n",
    "for folder in lis_folders:\n",
    "    lis_files = os.listdir(data_dir+folder+'\\.')\n",
    "    im = []\n",
    "    for files in lis_files:\n",
    "        img = '\\\\'.join([data_dir,folder,files])\n",
    "        image = plt.imread(img)\n",
    "        im.append(image.flatten().reshape(-1,1))\n",
    "    im_np = np.array(im)[:,:,0]\n",
    "    # print(im_np.shape)\n",
    "    im_np = np.append(im_np,cur_class*np.ones((im_np.shape[0],1)),axis=1)\n",
    "    # print(im_np.shape)\n",
    "    cur_class+=1\n",
    "    X.append(im_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "X_train = X[0]\n",
    "for x in X[1:]: \n",
    "    X_train = np.append(X_train,x,axis=0)\n",
    "X_pca = X_train\n",
    "pca.fit(X_pca[:,:-1])\n",
    "X_pca[:,-3:-1] = pca.transform(X_pca[:,:-1])\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pcaa = X_pca[:,-3:]\n",
    "np.random.shuffle(X_pcaa)\n",
    "\n",
    "def import_dataset(X_pcaa,split_percent = 70):\n",
    "    \n",
    "    X = X_pca[:,:-1]\n",
    "    y = X_pca[:,-1:]\n",
    "    datasize = X.shape[0]\n",
    "\n",
    "    split_point = split_percent//10\n",
    "\n",
    "    X_train = X[:(datasize*split_point)//10,:]\n",
    "    y_train = y[:(datasize*split_point)//10,:]\n",
    "    X_test = X[(datasize*split_point)//10:,:]\n",
    "    y_test = y[(datasize*split_point)//10:,:]\n",
    "\n",
    "    return(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_pca[:30,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dash = X\n",
    "# # X_dash[1] = X_updated.reshape(-1,4096,1)\n",
    "# X_np = np.array(X_dash)\n",
    "# print(X_np.shape)\n",
    "# X_train = X[0]\n",
    "# for x in X[1:]:\n",
    "#     X_train = np.append(X_train,x,axis=0)\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_edit = X[1]\n",
    "# X_edit = np.array(X_edit)\n",
    "# X_mean = np.sum(X_edit, axis=0) / X_edit.shape[0]\n",
    "# X_mean = X_mean.reshape(1,-1)\n",
    "# print(X_mean.shape)\n",
    "# diff = X[0].shape[0]-X[1].shape[0]\n",
    "# oneer = np.ones((diff,1))\n",
    "# X_app = np.dot(oneer,X_mean)\n",
    "# X_updated = np.append(X_edit,X_app,axis=0)\n",
    "# print(X_updated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train):\n",
    "    training_size = X_train.shape[0]\n",
    "    X_mean = np.sum(X_train,axis=0) / training_size\n",
    "    X_var = np.sqrt(np.sum((np.square(X_train-X_mean)),axis=0)/training_size)\n",
    "    X_train_reg = (X_train - X_mean) / X_var\n",
    "\n",
    "    return (X_mean,X_var,X_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,y_train,X_test,y_test,k_num,feat_scal=False):\n",
    "\n",
    "    num_class = 6\n",
    "    test_size = X_test.shape[0]\n",
    "    train_size = X_train.shape[0]\n",
    "    if feat_scal:\n",
    "        X_m,X_v,X_r = feature_scaling(X_train)\n",
    "        X_test_reg = (X_test-X_m)/X_v\n",
    "    else:\n",
    "        X_r = X_train\n",
    "        X_test_reg = X_test\n",
    "    \n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(test_size):\n",
    "        sample_X = X_test_reg[i:i+1,:]\n",
    "        sample_y = y_test[i,:]\n",
    "        dist_vec = np.sqrt(np.sum(np.square(X_r-sample_X),axis=1))\n",
    "        dist_vec = dist_vec.reshape((train_size,1))\n",
    "\n",
    "        d = np.column_stack((dist_vec[:,:],y_train[:,0]))\n",
    "        # print(d)\n",
    "\n",
    "        sorted_dist = d[np.argsort(d[:, 0])]\n",
    "        y_val_vector = sorted_dist[:k_num,1].reshape(-1,1)\n",
    "        class_sizes = []\n",
    "        for j in range(num_class):\n",
    "            num = y_val_vector[ y_val_vector[:,0]==j ].shape[0]\n",
    "            class_sizes.append([num,j])\n",
    "        class_sizes.sort(reverse=True)\n",
    "        y_pred.append(class_sizes[0][1])   \n",
    "    \n",
    "    y_pred = np.array(y_pred).reshape(-1,1)\n",
    "\n",
    "    # print(y_pred.shape)\n",
    "    return y_pred\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_test):\n",
    "\n",
    "    # y_pred = y_pred.reshape(-1,1)\n",
    "    print('MSE LOSS')\n",
    "    mse_loss = np.sum(np.square((y_test-y_pred)),axis=0) / y_test.shape[0]\n",
    "    print(mse_loss)\n",
    "    print('............................................................................')\n",
    "    print('MAE LOSS')\n",
    "    mae_loss = np.sum(np.abs((y_test-y_pred)),axis=0) / y_test.shape[0]\n",
    "    print(mae_loss)\n",
    "    # print('............................................................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = import_dataset(X_pcaa)\n",
    "print('model run initiated...')\n",
    "y_pred = KNN(X_train,y_train,X_test,y_test,50,False)\n",
    "print('model run completed')\n",
    "accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}