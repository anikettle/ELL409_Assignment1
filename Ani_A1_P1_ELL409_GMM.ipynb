{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(split_percent = 70):\n",
    "    dataset = pd.read_csv('E:\\ELL_project\\problem1\\health_data.csv')\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "    X = dataset.iloc[:,:-1].values\n",
    "    y = dataset.iloc[:,-1:].values\n",
    "    datasize = X.shape[0]\n",
    "\n",
    "    split_point = split_percent//10\n",
    "\n",
    "    X_train = X[:(datasize*split_point)//10,:]\n",
    "    y_train = y[:(datasize*split_point)//10,:]\n",
    "    X_test = X[(datasize*split_point)//10:,:]\n",
    "    y_test = y[(datasize*split_point)//10:,:]\n",
    "\n",
    "    return(X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test):\n",
    "    X_mean = np.sum(X_train,axis=0)\n",
    "    X_var = np.sqrt(np.sum(np.square(X_train - X_mean), axis=0))\n",
    "\n",
    "    X_train_feat_scaled = (X_train - X_mean ) / X_var\n",
    "    X_test_feat_scaled = (X_test - X_mean) / X_var\n",
    "\n",
    "    return (X_mean,X_var, X_train_feat_scaled,X_test_feat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_01(X_train,y_train):\n",
    "    x_0_train = X_train[y_train[:,0]==0]\n",
    "    x_1_train = X_train[y_train[:,0]==1]\n",
    "    return(x_0_train,x_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_generate_models(num_feat,modes_1=3,modes_0=3):\n",
    "    para_0 = []\n",
    "    para_1 = []\n",
    "    for i in range(modes_1):\n",
    "        m = np.random.rand(1,num_feat)\n",
    "        v = np.random.rand(num_feat,num_feat)\n",
    "        para_1.append((1/modes_1,m,v))           # 1: prior 2: mean 3: covariance\n",
    "    for i in range(modes_0):\n",
    "        m = np.random.rand(1,num_feat)\n",
    "        v = np.random.rand(num_feat,num_feat)\n",
    "        para_0.append((1/modes_0,m,v))          # 1: prior 2: mean 3: covariance\n",
    "    return(modes_1,modes_0,para_1,para_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob(X,meu,cov):\n",
    "    num_of_feat = cov.shape[0]\n",
    "    det = np.linalg.det(cov)\n",
    "    p0 = 1/math.pow((2*math.pi),num_of_feat/2)\n",
    "    p0 = p0 / (det**0.5)\n",
    "    # p = np.exp(-0.5 * (np.dot(X-meu,np.linalg.inv(cov)))*(X-meu))\n",
    "    p = np.exp(-0.5 * np.sum(np.multiply(np.dot(X-meu,np.linalg.inv(cov)) , (X-meu)),axis=1).reshape(-1,1))\n",
    "    # print('here',X.shape,meu.shape,cov.shape,p.shape)    \n",
    "    return (p*p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_alpha_mean_var(modes,prob,X_train):\n",
    "    num_elements = X_train.shape[0]\n",
    "    num_in_class_i = {}\n",
    "    all_probs = prob[0]\n",
    "    updated_params = []\n",
    "\n",
    "    # print(prob[0].shape)\n",
    "\n",
    "    for i in range(1,modes):\n",
    "        all_probs = np.append(all_probs,prob[i],axis=1)\n",
    "    mode_distribute = np.argmax(all_probs,axis=1)\n",
    "    for i in range(modes):\n",
    "        class_i = np.zeros((num_elements))\n",
    "        class_i[[mode_distribute==i]] = 1\n",
    "        num_in_class_i[i] = np.sum(class_i,axis=0)\n",
    "\n",
    "        # print('herenow',prob[i].shape)\n",
    "\n",
    "        u_m = np.dot(np.transpose(prob[i]),X_train) / np.sum(prob[i],axis=0)\n",
    "        dif = X_train - u_m\n",
    "        u_c = np.dot(np.transpose(dif),dif) / num_elements\n",
    "\n",
    "        updated_params.append( (num_in_class_i[i]/num_elements , u_m , u_c) )\n",
    "    \n",
    "    return ( updated_params )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_optimize(X_train,modes,params):\n",
    "    num_points = X_train.shape[0]\n",
    "    alpha = {}\n",
    "    meu = {}\n",
    "    covar = {}\n",
    "    prob = {}\n",
    "    sum_mat = np.zeros((params[0][1].shape[0],1))\n",
    "\n",
    "    for i in range(modes):\n",
    "        alpha[i],meu[i],covar[i] = params[i]\n",
    "        prob[i] = calc_prob(X_train,meu[i],covar[i])\n",
    "        # print('checkk',prob[i].shape)\n",
    "        prob[i] = prob[i] * alpha[i]\n",
    "        sum_mat = sum_mat + prob[i]\n",
    "    for i in range(modes):\n",
    "        prob[i] = prob[i] / sum_mat\n",
    "    \n",
    "    updated_params = ret_alpha_mean_var(modes,prob,X_train)\n",
    "\n",
    "    return(updated_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_the_params(X_train,modes,params,iter=100):\n",
    "    updated_params = params\n",
    "    for iterator in range(iter):\n",
    "        updated_params = one_step_optimize(X_train,modes,params)\n",
    "    \n",
    "    return (updated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_training(X_train, y_train, modes_1 = 3, modes_0 = 3):\n",
    "    X_0_train,X_1_train = sep_01(X_train,y_train)\n",
    "    num_feat = X_train.shape[1]\n",
    "    modes_1,modes_0,para_1,para_0 = random_generate_models(num_feat,modes_1,modes_0)\n",
    "    opt_para_0 = optimize_the_params(X_0_train,modes_0,para_0)\n",
    "    opt_para_1 = optimize_the_params(X_1_train,modes_1,para_1)\n",
    "\n",
    "    return(opt_para_0,opt_para_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_testing(X_test,y_test, opt_para_0, opt_para_1, modes_1 = 3, modes_0 = 3):\n",
    "    test_size = X_test.shape[0]\n",
    "    prob_0, prob_1 = np.zeros((test_size,1)) , np.zeros((test_size,1))\n",
    "    for i in range(modes_1):\n",
    "        alpha,meu,cov = opt_para_1[i]\n",
    "        prob = alpha*calc_prob(X_test,meu,cov)\n",
    "        prob_1 += prob\n",
    "    for i in range(modes_0):\n",
    "        alpha,meu,cov = opt_para_0[i]\n",
    "        prob = alpha*calc_prob(X_test,meu,cov)\n",
    "        prob_0 += prob\n",
    "    all_probs = prob_0\n",
    "    all_probs = np.append(all_probs,prob_1,axis=1)\n",
    "    y_pred = np.argmax(all_probs,axis=1)\n",
    "\n",
    "    return (y_pred.reshape(-1,1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metrics(y_pred_thresh, y_test):\n",
    "\n",
    "    print(y_pred_thresh.shape,y_test.shape)\n",
    "\n",
    "    test_size = y_test.shape[0]\n",
    "\n",
    "    tp = np.sum((y_pred_thresh+y_test)==2 , axis=0)[0]\n",
    "    tn = np.sum(y_pred_thresh==y_test , axis=0)[0] - tp\n",
    "    fp = np.sum(y_pred_thresh , axis=0)[0]-tp\n",
    "    fn = test_size-tp-tn-fp\n",
    "\n",
    "\n",
    "    print('tp: {} , tn: {} , fp: {} , fn: {}'.format(tp,tn,fp,fn))\n",
    "\n",
    "    acc = (tp+tn)/test_size\n",
    "    prec = (tp)/(tp+fp)\n",
    "    recl = (tp)/(tp+fn)\n",
    "    f1 = 2*prec*recl/(prec+recl)\n",
    "\n",
    "    print('Accuracy: {}'.format( acc  ))\n",
    "    print('Precision: {}'.format( prec  ))\n",
    "    print('Recall: {}'.format( recl  ))\n",
    "    print('F1 score: {}'.format( f1  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(modes_0=3,modes_1=3):\n",
    "    X_train,X_test,y_train,y_test = import_dataset()\n",
    "    opt_para_0,opt_para_1 = GMM_training(X_train, y_train, modes_1, modes_0)\n",
    "    y_pred = GMM_testing(X_test,y_test, opt_para_0, opt_para_1, modes_1, modes_0)\n",
    "    accuracy_metrics(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(210, 1) (210, 1)\ntp: 0 , tn: 123 , fp: 0 , fn: 87\nAccuracy: 0.5857142857142857\nPrecision: nan\nRecall: 0.0\nF1 score: nan\n"
     ]
    }
   ],
   "source": [
    "run_model(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}