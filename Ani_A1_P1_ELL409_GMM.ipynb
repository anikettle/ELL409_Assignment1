{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(split_percent = 70):\n",
    "    dataset = pd.read_csv('E:\\ELL_project\\problem1\\health_data.csv')\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "    X = dataset.iloc[:,:-1].values\n",
    "    y = dataset.iloc[:,-1:].values\n",
    "    datasize = X.shape[0]\n",
    "\n",
    "    split_point = split_percent//10\n",
    "\n",
    "    X_train = X[:(datasize*split_point)//10,:]\n",
    "    y_train = y[:(datasize*split_point)//10,:]\n",
    "    X_test = X[(datasize*split_point)//10:,:]\n",
    "    y_test = y[(datasize*split_point)//10:,:]\n",
    "\n",
    "    return(X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test):\n",
    "    X_mean = np.sum(X_train,axis=0)\n",
    "    X_var = np.sqrt(np.sum(np.square(X_train - X_mean), axis=0))\n",
    "\n",
    "    X_train_feat_scaled = (X_train - X_mean ) / X_var\n",
    "    X_test_feat_scaled = (X_test - X_mean) / X_var\n",
    "\n",
    "    return (X_mean,X_var, X_train_feat_scaled,X_test_feat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_01(X_train,y_train):\n",
    "    x_0_train = X_train[y_train[:,0]==0]\n",
    "    x_1_train = X_train[y_train[:,0]==1]\n",
    "    return(x_0_train,x_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_generate_models(moodes_1=3,modes_0=3,num_feat):\n",
    "    para_0 = []\n",
    "    para_1 = []\n",
    "    for i in range(modes_1):\n",
    "        m = np.random.rand(1,num_feat)\n",
    "        v = np.random.rand(num_feat,num_feat)\n",
    "        para_1.append((1/modes_1,m,v))           # 1: prior 2: mean 3: covariance\n",
    "    for i in range(modes_0):\n",
    "        m = np.random.rand(1,num_feat)\n",
    "        v = np.random.rand(num_feat,num_feat)\n",
    "        para_0.append((1/modes_0,m,v))          # 1: prior 2: mean 3: covariance\n",
    "    return(modes_1,modes_0,para_1,para_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_the_params(X_train,modes,params):\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_modelling(X_train, y_train, modes_1 = 3, modes_0 = 3):\n",
    "    X_0_train,X_1_train = sep_01(X_train,y_train)\n",
    "    modes_1,modes_0,para_1,para_0 = random_generate_models(modes_1,modes_0,num_feat)\n",
    "    opt_para_0 = optimize_the_params(X_0_train,modes_0,para_0)\n",
    "    opt_para_1 = optimize_the_params(X_1_train,modes_1,para_1)\n",
    "    "
   ]
  }
 ]
}