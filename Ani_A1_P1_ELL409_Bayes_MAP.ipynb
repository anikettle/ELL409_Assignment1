{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For prior assumpsion, we take the medically known values and some rough assumptions on our behalf-\n",
    "For y=0\n",
    "    Age - 30 (Younger people usually have higher tendency)\n",
    "    Rest Blood Pressure - 120 (According to my understanding of what I obtained from the internet)\n",
    "    Cholestrol Level - 162.5 (125 to 200 - we bluntly take the average, therefore, = 162.5)\n",
    "    \n",
    "For y=1\n",
    "    Age - 60 \n",
    "    Rest Blood Pressure - 150 \n",
    "    Cholestrol Level - 200 \n",
    "\n",
    "Variance we randomly take as 1 across all features and covariance as 0 (We will vary it and see the results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(split_percent = 70):\n",
    "    dataset = pd.read_csv('E:\\ELL_project\\problem1\\health_data.csv')\n",
    "    dataset = dataset.sample(frac = 1)\n",
    "    X = dataset.iloc[:,:-1].values\n",
    "    y = dataset.iloc[:,-1:].values\n",
    "    datasize = X.shape[0]\n",
    "\n",
    "    split_point = split_percent//10\n",
    "\n",
    "    X_train = X[:(datasize*split_point)//10,:]\n",
    "    y_train = y[:(datasize*split_point)//10,:]\n",
    "    X_test = X[(datasize*split_point)//10:,:]\n",
    "    y_test = y[(datasize*split_point)//10:,:]\n",
    "\n",
    "    return(X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test):\n",
    "    X_mean = np.sum(X_train,axis=0)\n",
    "    X_var = np.sqrt(np.sum(np.square(X_train - X_mean), axis=0))\n",
    "\n",
    "    X_train_feat_scaled = (X_train - X_mean ) / X_var\n",
    "    X_test_feat_scaled = (X_test - X_mean) / X_var\n",
    "\n",
    "    return (X_mean,X_var, X_train_feat_scaled,X_test_feat_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_01(X_train,y_train):\n",
    "    x_0_train = X_train[y_train[:,0]==0]\n",
    "    x_1_train = X_train[y_train[:,0]==1]\n",
    "    return(x_0_train,x_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var(x):\n",
    "    siz = x.shape[0]\n",
    "    mean = np.sum(x,axis=0)/siz\n",
    "    dif = X-mean\n",
    "    covariance_matrix = np.dot(np.transpose(dif),dif) / siz\n",
    "\n",
    "    return(mean,covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_meu_var(m1,m2,m3,v1,v2,v3):\n",
    "    prior_mean = np.array([m1,m2,m3])\n",
    "    prior_variance = np.array([v1,v2,v3])\n",
    "    return(prior_mean,prior_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_n(meu0,meu,cov0,cov,data_size):\n",
    "    # Now, we will consider L as the left most value, M as the middle one and R as the right one in the formula for meu        # and cov matrix\n",
    "    l = cov0\n",
    "    m = np.inverse(cov0 + (cov/data_size))\n",
    "    r = cov/data_size\n",
    "\n",
    "    meu_n = np.dot(np.dot(l,m)meu) + np.dot(np.dot(r,m),meu0)\n",
    "    cov_n = np.dot(np.dot(l,m),r)\n",
    "\n",
    "    return (meu_n,cov_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var_data(X_train,y_train,prior_vals):\n",
    "    x_0,x_1 = sep_01(X_train,y_train)\n",
    "    meu_0,covar_0 = mean_var(x_0)\n",
    "    meu_1,covar_1 = mean_var(x_1)\n",
    "\n",
    "    prior_mean_var = gen_meu_var(prior_vals)\n",
    "    \n",
    "    prior_mean_0 = prior_mean_var[0]\n",
    "    prior_covar_0 = prior_mean_var[1]\n",
    "    prior_mean_1 = prior_mean_var[2]\n",
    "    prior_covar_1 = prior_mean_var[3]\n",
    "\n",
    "    size_0 = x_0.shape[0]\n",
    "    meu_n_0,cov_n_0 = ret_n(prior_mean_0,meu_0,prior_covar_0,covar_0,size_0)\n",
    "    size_1 = x_1.shape[0]\n",
    "    meu_n_1,cov_n_1 = ret_n(prior_mean_1,meu_1,prior_covar_1,covar_1,size_1)\n",
    "\n",
    "    return(meu_n_0,cov_n_0, meu_n_1,cov_n_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_test()"
   ]
  }
 ]
}