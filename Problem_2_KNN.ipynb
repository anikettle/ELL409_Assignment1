{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(split_percent = 70):\n",
    "    # dataset = pd.read_csv('E:\\ELL_Project\\problem2\\weather_data.csv')     \n",
    "    dataset = pd.read_excel('E:\\ELL_Project\\problem2\\weather_data.xlsx')                     \n",
    "    dataset = dataset.sample(frac = 1)\n",
    "    X = dataset.iloc[:,:-1].values\n",
    "    y = dataset.iloc[:,-1:].values\n",
    "    datasize = X.shape[0]\n",
    "\n",
    "    split_point = split_percent//10\n",
    "\n",
    "    X_train = X[:(datasize*split_point)//10,:]\n",
    "    y_train = y[:(datasize*split_point)//10,:]\n",
    "    X_test = X[(datasize*split_point)//10:,:]\n",
    "    y_test = y[(datasize*split_point)//10:,:]\n",
    "\n",
    "    return(X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_scaling(X_train):\n",
    "    training_size = X_train.shape[0]\n",
    "    X_mean = np.sum(X_train,axis=0) / training_size\n",
    "    X_var = np.sqrt(np.sum((np.square(X_train-X_mean)),axis=0)/training_size)\n",
    "    X_train_reg = (X_train - X_mean) / X_var\n",
    "\n",
    "    return (X_mean,X_var,X_train_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X_train,y_train,X_test,y_test,k_num,feat_scal=True):\n",
    "\n",
    "    test_size = X_test.shape[0]\n",
    "    train_size = X_train.shape[0]\n",
    "    # X_m,X_v,X_r,y_m,y_v,y_r = feature_scaling(X_train,y_train)\n",
    "    if feat_scal:\n",
    "        X_m,X_v,X_r = feature_scaling(X_train)\n",
    "        X_test_reg = (X_test-X_m)/X_v\n",
    "    else:\n",
    "        X_r = X_train\n",
    "        X_test_reg = X_test\n",
    "    # y_test_reg = (y_test-y_m)/y_v\n",
    "    y_pred = np.array([])\n",
    "    # print(y_pred)\n",
    "    for i in range(test_size):\n",
    "        sample_X = X_test_reg[i:i+1,:]\n",
    "        sample_y = y_test[i,:]\n",
    "        dist_vec = np.sqrt(np.sum(np.square(X_r-sample_X),axis=1))\n",
    "        dist_vec = dist_vec.reshape((train_size,1))\n",
    "\n",
    "        d = np.column_stack((dist_vec[:,:],y_train[:,0]))\n",
    "        # print(d)\n",
    "\n",
    "        sorted_dist = d[np.argsort(d[:, 0])]\n",
    "        temp_distance_vector = sorted_dist[:k_num,0]\n",
    "        distance_vector = temp_distance_vector.reshape(-1,1)\n",
    "        # distance_vector = np.append(np.ones(distance_vector.shape),distance_vector)\n",
    "        # print(distance_vector.shape)\n",
    "        for j in np.arange(0,10,0.5):\n",
    "            distance_vector = np.append(distance_vector,(temp_distance_vector**j).reshape(-1,1),axis=1)\n",
    "        distance_vector = distance_vector[:,1:]\n",
    "        # print(distance_vector.shape)\n",
    "        ddd = np.sum(distance_vector,axis=0).reshape(1,-1)\n",
    "        # print(ddd[0,0])\n",
    "        # print(ddd.shape)\n",
    "\n",
    "        y_val_vector = sorted_dist[:k_num,1].reshape(-1,1)\n",
    "        # print(y_val_vector.shape)\n",
    "        # print(distance_vector.shape)\n",
    "        # print(ddd.shape)\n",
    "        num1 = np.dot(np.transpose(y_val_vector),distance_vector) / ddd\n",
    "        # print(num1.shape)\n",
    "        # num1 = np.max(num1)\n",
    "        if i==0:\n",
    "            # print('check')\n",
    "            y_pred = num1.reshape(1,-1)\n",
    "        else:\n",
    "            # print(y_pred.shape)\n",
    "            y_pred = np.append(y_pred,num1.reshape(1,-1),axis=0)\n",
    "            \n",
    "\n",
    "    # print(y_pred.shape)\n",
    "    return y_pred\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred,y_test):\n",
    "\n",
    "    # y_pred = y_pred.reshape(-1,1)\n",
    "    print('MSE LOSS')\n",
    "    mse_loss = np.sum(np.square((y_test-y_pred)),axis=0) / y_test.shape[0]\n",
    "    print(mse_loss)\n",
    "    print('............................................................................')\n",
    "    print('MAE LOSS')\n",
    "    mae_loss = np.sum(np.abs((y_test-y_pred)),axis=0) / y_test.shape[0]\n",
    "    print(mae_loss)\n",
    "    # print('............................................................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MSE LOSS\n[2.00623067 2.19407759 2.37097801 2.53666417 2.6914236  2.83582265\n 2.97055692 3.0963647  3.21397723 3.32409174 3.42735847 3.52437586\n 3.61569033 3.70179855 3.78315069 3.8601543  3.93317804 4.00255543\n 4.06858822 4.13154954]\n............................................................................\nMAE LOSS\n[0.97126667 1.01689978 1.05797179 1.09507075 1.12835438 1.15849231\n 1.18582385 1.21083836 1.2335726  1.25440691 1.27371248 1.29149648\n 1.30803281 1.32373422 1.33835682 1.35220475 1.36534539 1.37771173\n 1.3895756  1.40123372]\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = import_dataset()\n",
    "y_pred = KNN(X_train,y_train,X_test,y_test,50,False)\n",
    "accuracy(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}